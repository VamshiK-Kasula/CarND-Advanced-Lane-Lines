{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Advanced Lane Finding Project\n","\n","The goals / steps of this project are the following:\n","\n","* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n","* Apply a distortion correction to raw images.\n","* Use color transforms, gradients, etc., to create a thresholded binary image.\n","* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n","* Detect lane pixels and fit to find the lane boundary.\n","* Determine the curvature of the lane and vehicle position with respect to center.\n","* Warp the detected lane boundaries back onto the original image.\n","* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Computing the camera calibration matrix and distortion coefficients given a set of chessboard images.\n","\n","import numpy as np\n","import cv2\n","import glob\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib qt \n","\n","# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n","nx = 9 # the number of inside corners in x\n","ny = 6 # the number of inside corners in y\n","objp = np.zeros((ny*nx,3), np.float32)\n","objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n","# Arrays to store object points and image points from all the images.\n","objpoints = [] # 3d points in real world space\n","imgpoints = [] # 2d points in image plane.\n","\n","# Make a list of calibration images\n","images = glob.glob('./camera_cal/*.jpg')\n","# Step through the list and search for chessboard corners\n","for fname in images:\n","    img = cv2.imread(fname)\n","    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","\n","    # Find the chessboard corners\n","    ret, corners = cv2.findChessboardCorners(gray, (nx,ny),None)\n","    # If found, add object points, image points\n","    if ret == True:\n","        objpoints.append(objp)\n","        imgpoints.append(corners)\n","\n","        # Draw and display the corners\n","        img = cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n","        cv2.imshow('img',img)\n","        # cv2.waitKey(500)\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(720, 1280, 3)\n(720, 1280)\n"}],"source":["# Applying distortion correction to raw images and perspective transform\n","images = glob.glob('./camera_cal/*.jpg')\n","offset = 100\n","for fname in images:\n","    img = cv2.imread(fname)\n","    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","    img_size = (gray.shape[1], gray.shape[0])\n","\n","\n","    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n","\n","    if ret == True:\n","    # Applying distortion correction\n","        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1],None, None)\n","        undist = cv2.undistort(img,  mtx, dist, None, mtx)\n","\n","        # Applying perspective transform\n","        src = np.float32([corners[0], corners[nx-1], corners[-1], corners[-nx]])\n","        dst = np.float32([[offset, offset], [img_size[0]-offset, offset], [img_size[0]-offset, img_size[1]-offset],[offset, img_size[1]-offset]])\n","        perscpective_transform_mat = cv2.getPerspectiveTransform(src, dst)\n","        warped = cv2.warpPerspective(undist, perscpective_transform_mat, img_size, flags=cv2.INTER_LINEAR)\n","\n","        cv2.imshow('img',warped)\n","        cv2.waitKey(500)\n","        name = \"./cal_out\" + fname.replace('./camera_cal', '')\n","        cv2.imwrite( name, warped )\n","cv2.destroyAllWindows()\n","\n","print(img.shape)\n","gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","print(gray.shape)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Applying a perspective transform to rectify binary image.\n","\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# x and y sobel Gradients\n","def mag_gradient(img, sobel_kernel, mag_thresh=(0, 255)):\n","    # Convert to grayscale\n","    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","    # Sobel x gradients\n","    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n","    # Sobel Y gradients\n","    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n","    # Calculate the gradient magnitude\n","    grad_mag = np.sqrt(sobel_x**2 + sobel_y**2)\n","    # Rescale to 8 bit\n","    scale_factor = np.max(grad_mag)/255 \n","    grad_mag = (grad_mag/scale_factor).astype(np.uint8) \n","    # Create a binary image of ones where threshold is met, zeros otherwise\n","    binary_output = np.zeros_like(grad_mag)\n","    binary_output[(grad_mag >= mag_thresh[0]) & (grad_mag <= mag_thresh[1])] = 1\n","\n","    # Return the binary image\n","    return binary_output\n","\n","# S-channel thresholding\n","def hls_threshold(img):\n","    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n","    s_channel = hls[:,:,2]\n","    binary_s_output = np.zeros_like(s_channel)\n","    binary_s_output[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n","\n","    return s_channel, binary_s_output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"./test_images/test3.jpg\n./test_images/test2.jpg\n./test_images/test5.jpg\n./test_images/test4.jpg\n./test_images/test6.jpg\n./test_images/test1.jpg\n./test_images/straight_lines2.jpg\n./test_images/straight_lines1.jpg\n"}],"source":["# Use color transforms, gradients, etc., to create a thresholded binary image.\n","thresh=(90, 255)\n","images = glob.glob('./test_images/*.jpg')\n","f, ((ax1, ax2),(ax3, ax4)) = plt.subplots(2, 2, figsize=(24, 9))\n","mag_thresh = (30,100)\n","for fname in images:\n","    img = mpimg.imread(fname) #RGB image\n","\n","    mag_binary = mag_gradient(img, 3, mag_thresh)\n","    s_channel, binary_s_output= hls_threshold(img)\n","    # hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n","    # s_channel = hls[:,:,2]\n","    # binary_s_output = np.zeros_like(s_channel)\n","    # binary_s_output[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n","\n","    ax1.imshow(img)\n","    ax1.set_title('Original Image', fontsize=50)\n","    ax2.imshow(s_channel, cmap='gray')\n","    ax2.set_title('S Channel', fontsize=50)\n","    ax3.imshow(mag_binary, cmap='gray')\n","    ax3.set_title('Gradient', fontsize=50)\n","    ax4.imshow(binary_s_output, cmap='gray')\n","    ax4.set_title('Thresholded S', fontsize=50)\n","    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n","    plt.pause(1)\n","    print(fname)\n","plt.close('all')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.4"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}